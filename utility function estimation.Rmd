---
title: "Stage 1 Utility Function Estimation"
author: "Wei-Lun, Lin"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

library(rstan)
library(bayesplot)
library(posterior)
# library(loo)
```


## Data Reading and Processing

We first get raw data from folders of 2021, 2022 and 2023.
The format of the data in 2021 is a little different from those in 2022 and 2023, 
so we need to separate different cases.

```{r get-rawdata}
# get rawdata from folders of 2021-2023
rawdata <- data.frame()
files.dir <- list.files("./data/raw_data", full.names=T)[-16]
for (i in 1:length(files.dir)) {
  path <- paste0(files.dir[i], "/rawData")
  files <- list.files(path, pattern=".csv", full.names=T)
  for (file in files) {
    if (i < 7) subj.data <- read.csv(file)[, 1:247]
    else subj.data <- read.csv(file)[, 2:248]
    subj <- str_split_i(file, "/", i=6) %>% 
      str_split_i("_EDP", i=1)
    # print(subj)
    subj.data$subj <- subj
    rawdata <- rbind(rawdata, subj.data)
  }
}
rm(i, subj.data, file, files, files.dir, path, subj)

dim(rawdata)
head(rawdata[, 1:5])
write.csv(rawdata, "./data/preprocessed_data/rawdata.csv", row.names=F)
```

We have 165 subjects in total.

The extracted raw data contains action time points, values and choices.
To note that, we do not need the time point data, so we remove them next.

```{r remove-RT--add-subj-id}
rawdata <- read.csv("./data/preprocessed_data/rawdata.csv")
col.target <- c(
  seq(3, 247, 13), 
  seq(4, 247, 13),
  seq(13, 247, 13)
) %>% 
  sort()
colnames(rawdata)[248] <- "subject"
rawdata <- rawdata[, c(248, col.target)]
rawdata <- rawdata %>% 
  mutate(
    subj_id = row_number()
  ) %>% 
  relocate(subj_id)
rm(col.target)

head(rawdata[, 1:5])
```

As the part of the data showed above, there are several problems about the content of the data.

 + Columns contain strings of list structure in Python. For example, a possible element could be `"[1000, 800, 600, 400, 200, 100, None, None, 100]"` or `"['A', 'B', 'B', 'A', 'A']"`. These strings should be convert to vectors.
 + There are elements in lists that should be discard. For example, the 6th to 9th elements in value list have no corresponding choice data.
 + The structure of the data frame should allow us to easily analysis the data. For example, each trial should be in a single row.
 + The raw data contained only the value being measured, not all the outcomes of lotteries. Thus, the outcomes should be find out according to the experiment setting.
 + Some subjects did not react to the lotteries in some trials, so there are no choice data in these trials. These trials should be discarded.

To convert the strings to value vectors, I used the `fromJSON()` function in package `jsonlite` to parse the string of list, and convert elements into vector.
Besides, the function automatically detected the type of the elements, which was convenient.

To discard some elements that will not be used, I simply take the top 5 elements in value vectors.

To add additional experiment settings, I took value lists and added other outcomes manually row-wise.

```{r to-trial-structure}
parse_list_string <- function(x) {
  # replace '' and None
  x <- gsub("None", "null", x)
  x <- gsub("'", '"', x)
  # parse the string
  res <- jsonlite::fromJSON(x)
  res <- if(length(res) == 0) NA else res
  return(res)
}

remove_excess_info <- function(vec) {
  vec[1:5]
}

trial_seq <- Vectorize(seq.default, vectorize.args = c("from", "to"))
pos_seq <- trial_seq(from=26:30, to=91:95, by=10) %>% as.vector %>% sort
neg_seq <- trial_seq(from=31:35, to=91:95, by=10) %>% as.vector %>% sort

preproc_data <- rawdata %>%
  mutate(
    across(-c(subj_id, subject), ~map(.x, parse_list_string)),  # make python list into R vector
    across(ends_with("_list"), ~map(.x, remove_excess_info))  # make value list length be 5
  ) %>% 
  rowwise() %>% 
  transmute(  # add lottery outcomes
    subj_id = subj_id,
    subject = subject,
    trial = list(c(1:25, pos_seq, neg_seq)),
    xA1 = list(c(
      rep(2000, 10), rep(0, 10), rep(300, 5), 
      rep(x1pos[[1]], 5), rep(x2pos[[1]], 5), rep(x3pos[[1]], 5), rep(x4pos[[1]], 5), rep(x5pos[[1]], 5), rep(x6pos[[1]], 5), rep(x7pos[[1]], 5),
      rep(300, 35)
    )),
    xA2 = list(c(
      L_list, rep(0, 5), rep(L[[1]], 5), rep(-300, 5), rep(0, 5), 
      rep(-300, 35),
      rep(x1neg[[1]], 5), rep(x2neg[[1]], 5), rep(x3neg[[1]], 5), rep(x4neg[[1]], 5), rep(x5neg[[1]], 5), rep(x6neg[[1]], 5), rep(x7neg[[1]], 5)
    )),
    xB1 = list(c(
      rep(0, 5), x1pos_list, x1neg_list, rep(x1pos[[1]], 5), G2_list, 
      x2pos_list, x3pos_list, x4pos_list, x5pos_list, x6pos_list, x7pos_list, x8pos_list,
      rep(G2[[1]], 35)
    )),
    xB2 = list(c(
      rep(0, 5), x1pos_list, x1neg_list, L2_list, rep(x1neg[[1]], 5), 
      rep(L2[[1]], 35),
      x2neg_list, x3neg_list, x4neg_list, x5neg_list, x6neg_list, x7neg_list, x8neg_list
    )),
    choice = list(c(
      L_choice_list, x1pos_choice_list, x1neg_choice_list, L2_choice_list, G2_choice_list,
      x2pos_choice_list, x3pos_choice_list, x4pos_choice_list, x5pos_choice_list, x6pos_choice_list, x7pos_choice_list, x8pos_choice_list,
      x2neg_choice_list, x3neg_choice_list, x4neg_choice_list, x5neg_choice_list, x6neg_choice_list, x7neg_choice_list, x8neg_choice_list
    ))
  ) %>%
  unnest(c(trial, starts_with("x"), choice)) %>%   # 1 row 1 trial
  ungroup() %>% 
  arrange(subj_id, trial) %>% 
  drop_na() %>%   # remove rows that did not response
  mutate(choice = as.integer(choice == "A"))  # make "choose A" as 1

# preproc_data %>% write.csv("./data/preprocessed_data/preproc_data.csv", row.names=F)

dim(preproc_data)
head(preproc_data)
```

We had 165 subjects, and each subject underwent up to 95 trials.


### Data from 2021 (87 Subjects)

We take out the 87 subjects who underwent the experiment in 2021.

```{r subject-2021}
preproc_data.2021 <- preproc_data %>% 
  filter(subj_id <= 87)

str(preproc_data.2021)
preproc_data.2021$subject %>% unique()

# preproc_data.2021 %>% write.csv("./data/preprocessed_data/preproc_data-2021.csv", row.names=F)
```


## Cumulative Prospect Theory (CPT)

The subjective value $V$ of prospect $O$ can be determined by

$$
V(O)=\sum\pi(p_i)v(x_i)
$$

, where $\pi(\cdot)$ is the probability weighting function and $v(\cdot)$ is the value function.

The subjective value of payoff $x$ is defined as

$$
v(x)=
\left\{
  \begin{aligned}
      &x^\alpha, &&\text{if}\ x \geq 0  \\
      &-\lambda(-x)^\beta, &&\text{if}\ x < 0,
  \end{aligned}
\right.
$$

The probability weighting function (Tversky & Kahneman, 1992) considered in only 2 cases can be reduced to

$$
\pi(p_i)=\frac{p_i^c}{[p_i^c-(1-p_i)^c]^{1/c}}
$$

, with $c=\gamma$ for gains and $c=\delta$ for losses.
A probability function is more S-shaped with smaller $c$.
However, the setting of our experiment made every probabilities of outcomes be $0.5$.
Thus, we removed the probability weighting part from our model, and set $\pi(0.5)=0.5$.

The logistic choice rule is

$$
p(A, B)=\frac{1}{1+\exp[\phi(V(B)-V(A))]}
$$

where $\phi>0$ is a sensitivity parameter.
The choice behavior is more deterministic with larger $\phi$.

To sum up, CPT has 6 parameters: $\alpha \in [0, 1]$, $\beta \in [0, 1]$, $\lambda \in (0, \infty)$ and $\phi \in (0, \infty)$.

+ $\alpha$ quantifies the curvature of the subjective value function for gains;
+ $\beta$ quantifies the curvature of the subjective value function for losses;
+ $\lambda$ quantifies loss aversion;
+ $\phi$ quantifies the extent to which choice behavior is guided by subjective values.


### Parameter Setting

Parameters $\alpha_i$ and $\beta_i$ were first transformed to probit scale: 
$\alpha_i^\phi = \Theta^{-1}(\alpha_i)$ and $\beta_i^\phi = \Theta^{-1}(\beta_i)$.
Thus, $\alpha^\phi, \beta^\phi \in \mathbb{R}$.

Next, we assumed these subject-level parameters come from group-level normal distributions: 
$\alpha^\phi_i \sim N(\mu^\alpha, \sigma^\alpha)$ and $\beta^\phi_i \sim N(\mu^\beta, \sigma^\beta)$.

Finally, we decided the priors to the group-level parameters:
$\mu^\alpha \sim N(0, 1)$, $\mu^\beta \sim N(0, 1)$, $\sigma^\alpha \sim U(0, 10)$ and $\sigma^\beta \sim U(0, 10)$.

The two remaining parameters are $\lambda$ and $\phi$, which can only take positive value.
We assumed they come from a lognormal distribution: $\lambda\sim LN(\mu^\lambda, \sigma^\lambda)$ and $\phi\sim LN(\mu^\phi, \sigma^\phi)$.
Since we want $\lambda, \phi \in [0.1, 5]$, the hyper-parameters are $\mu^\lambda\sim U(-2.3, 1.61)$, $\mu^\phi \sim U(-2.3, 1.61)$, $\sigma^\lambda\sim U(0, 1.13)$, and $\sigma^\phi \sim U(0, 1.13)$.


## CPT Model Fitting with MCMC

We ran MCMC to get the cumulative prospect theory (CPT) parameters.

However, we now have 3 models whose restrictions are different.
We have:

+ The full model whose parameters are $\alpha, \beta, \lambda, \phi$,
+ The first restricted model whose parameters are $\alpha, \beta, \lambda, \phi$, where $\alpha=\beta$,
+ The second restricted model whose parameters are $\alpha, \beta, \phi$. ($\lambda$ is removed)

```{r MCMC setting and data}
# read data
preproc_data.2021 <- read.csv("./data/preprocessed_data/preproc_data-2021.csv")

# Setup
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

# n <- 10
stan_data <- subj_trial_df %>%
  # filter(subj_id %in% 1:n) %>% 
  list(
    N    = nrow(.),
    S    = length(unique(.$subj_id)),
    subj = .$subj_id,
    y    = .$choice,
    xA1  = .$xA1,
    xA2  = .$xA2,
    xB1  = .$xB1,
    xB2  = .$xB2
  )
```


### Full Model

```{r CPT full model, cache=T}
# Fit model
fit_full <- stan(
  file = "./CPT_model/hierarchical_CPT_full.stan",
  data = stan_data,
  chains = 4,
  iter = 1e4,
  warmup = 1000,
  seed = 2025
  # control = list(adapt_delta = 0.95, max_treedepth = 15)
)

saveRDS(fit_full, file="./res/CPT_full_c-4_ite-1e4_warm-1e3.rds")
# fit_full <- readRDS(file="./res/CPT_full_c-4_ite-1e4_warm-1e3.rds")
# summary(fit_full)
```


### Restricted Model 1: $\alpha=\beta$

```{r CPT alpha=beta}
fit_alpha.lambda <- stan(
  file = "./CPT_model/hierarchical_CPT_alpha-lambda.stan",
  data = stan_data,
  chains = 4,
  iter = 1e4,
  warmup = 1000,
  seed = 2025
  # control = list(adapt_delta = 0.95, max_treedepth = 15)
)

saveRDS(fit_alpha.lambda, file="./res/CPT_alpha-lambda_c-4_ite-1e4_warm-1e3.rds")
# fit_alpha.lambda <- readRDS(file="./res/CPT_alpha-lambda_c-4_ite-1e4_warm-1e3.rds")
```


### Restricted Model 2: No $\lambda$

```{r CPT no lambda}
fit_no.lambda <- stan(
  file = "./CPT_model/hierarchical_CPT_no-lambda.stan",
  data = stan_data,
  chains = 4,
  iter = 1e4,
  warmup = 1000,
  seed = 2025
  # control = list(adapt_delta = 0.95, max_treedepth = 15)
)

saveRDS(fit_no.lambda, file="./res/CPT_no-lambda_c-4_ite-1e4_warm-1e3.rds")
# fit_no.lambda <- readRDS(file="./res/CPT_no-lambda_c-4_ite-1e4_warm-1e3.rds")
```



### Model Fitting Results

```{r print full param}
n <- unique(subj_trial_df$subj_id) %>% 
  length()

params_full <- c(
  paste0("alpha[", 1:n, "]"), paste0("beta[", 1:n, "]"),
  paste0("lambda[", 1:n, "]"), paste0("phi[", 1:n, "]"),
  "mu_alpha", "mu_beta", "mu_loglambda", "mu_logphi"
)
options(max.print=999999)

sink(file = "./res/param/param_full.txt")
print(fit_full, pars = params_full)
sink(file = NULL)
```



```{r print res 1 param}
params_alpha.lambda <- c(
  paste0("alpha[", 1:n, "]"), paste0("lambda[", 1:n, "]"), paste0("phi[", 1:n, "]"),
  "mu_alpha", "mu_loglambda", "mu_logphi"
)

sink(file = "./res/param/param_res-1.txt")
print(fit_alpha.lambda, pars = params_alpha.lambda)
sink(file = NULL)
```


```{r print res 2 param}
params_no.lambda <- c(
  paste0("alpha[", 1:n, "]"), paste0("beta[", 1:n, "]"), paste0("phi[", 1:n, "]"),
  "mu_alpha", "mu_beta", "mu_logphi"
)

sink(file = "./res/param/param_res-2.txt")
print(fit_no.lambda, pars = params_no.lambda)
sink(file = NULL)
```


```{r summary 3 fits}
sink(file = "./res/param/summary.txt")
summary(fit_full, pars = c("mu_alpha", "mu_beta", "mu_loglambda", "mu_logphi"))$summary
summary(fit_alpha.lambda, pars = c("mu_alpha", "mu_loglambda", "mu_logphi"))$summary
summary(fit_no.lambda, pars = c("mu_alpha", "mu_beta", "mu_logphi"))$summary
sink(file = NULL)
```



